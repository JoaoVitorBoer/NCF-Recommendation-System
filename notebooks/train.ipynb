{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from models.MLP import MLP\n",
    "from models.GMF import GMF\n",
    "from models.NeuMF import NeuMF\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RATINGS_PATH = './data/preprocessed_data/ratings/ratings_preprocessed_ml.csv'\n",
    "JOKES_PATH = './data/preprocessed_data/jokes/jokes_preprocessed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"neumf-config.yaml\", \"r\") as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "ratings = pd.read_csv(RATINGS_PATH, sep=',', header=0)\n",
    "jokes = pd.read_csv(JOKES_PATH, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings['rating'] = (ratings['rating'] + 10) / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(ratings, shuffle=True, test_size=0.2, random_state=42)\n",
    "train_data, eval_data = train_test_split(train_data, shuffle=True, test_size=0.25, random_state=42)  \n",
    "\n",
    "user_train = train_data['user'].values\n",
    "item_train = train_data['joke_id'].values\n",
    "rating_train = train_data['rating'].values\n",
    "\n",
    "user_eval = eval_data['user'].values\n",
    "item_eval = eval_data['joke_id'].values\n",
    "rating_eval = eval_data['rating'].values\n",
    "\n",
    "user_test = test_data['user'].values\n",
    "item_test = test_data['joke_id'].values\n",
    "rating_test = test_data['rating'].values\n",
    "\n",
    "num_users = ratings['user'].nunique()\n",
    "num_items = ratings['joke_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 23:09:25.831406: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 23:09:25.842838: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 23:09:25.843016: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 23:09:25.856293: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 23:09:25.856475: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 23:09:25.856593: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 23:09:27.284396: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 23:09:27.284654: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 23:09:27.284799: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 23:09:27.284922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7880 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 1g.10gb, pci bus id: 0000:13:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716937768.712595     761 service.cc:145] XLA service 0x7ff6c80084d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1716937768.712674     761 service.cc:153]   StreamExecutor device (0): NVIDIA A100 80GB PCIe MIG 1g.10gb, Compute Capability 8.0\n",
      "2024-05-28 23:09:28.748894: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-28 23:09:31.326460: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8900\n",
      "2024-05-28 23:09:31.656110: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:742] The NVIDIA driver's CUDA version is 12.1 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716937774.589620     858 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_404', 3336 bytes spill stores, 3332 bytes spill loads\n",
      "\n",
      "I0000 00:00:1716937774.646799     883 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_402', 3336 bytes spill stores, 3332 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 118/2424\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.1103 - mae: 0.2813  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1716937775.484477     761 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0346 - mae: 0.1350 - val_loss: 0.0673 - val_mae: 0.1965\n",
      "Epoch 2/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0171 - mae: 0.0971 - val_loss: 0.0656 - val_mae: 0.1936\n",
      "Epoch 3/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0153 - mae: 0.0908 - val_loss: 0.0648 - val_mae: 0.1920\n",
      "Epoch 4/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0142 - mae: 0.0866 - val_loss: 0.0642 - val_mae: 0.1908\n",
      "Epoch 5/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0135 - mae: 0.0838 - val_loss: 0.0639 - val_mae: 0.1899\n",
      "Epoch 6/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0129 - mae: 0.0815 - val_loss: 0.0636 - val_mae: 0.1892\n",
      "Epoch 7/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0124 - mae: 0.0796 - val_loss: 0.0634 - val_mae: 0.1886\n",
      "Epoch 8/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0121 - mae: 0.0781 - val_loss: 0.0632 - val_mae: 0.1882\n",
      "Epoch 9/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0118 - mae: 0.0768 - val_loss: 0.0632 - val_mae: 0.1879\n",
      "Epoch 10/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0116 - mae: 0.0759 - val_loss: 0.0632 - val_mae: 0.1877\n",
      "Epoch 11/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0114 - mae: 0.0751 - val_loss: 0.0632 - val_mae: 0.1876\n",
      "Epoch 12/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0113 - mae: 0.0743 - val_loss: 0.0632 - val_mae: 0.1875\n",
      "Epoch 13/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0111 - mae: 0.0738 - val_loss: 0.0632 - val_mae: 0.1874\n",
      "Epoch 14/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0110 - mae: 0.0732 - val_loss: 0.0632 - val_mae: 0.1873\n",
      "Epoch 15/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0109 - mae: 0.0728 - val_loss: 0.0632 - val_mae: 0.1872\n",
      "Epoch 16/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0108 - mae: 0.0723 - val_loss: 0.0633 - val_mae: 0.1872\n",
      "Epoch 17/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0108 - mae: 0.0721 - val_loss: 0.0633 - val_mae: 0.1872\n",
      "Epoch 18/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0107 - mae: 0.0718 - val_loss: 0.0633 - val_mae: 0.1871\n",
      "Epoch 19/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0107 - mae: 0.0715 - val_loss: 0.0633 - val_mae: 0.1871\n",
      "Epoch 20/20\n",
      "\u001b[1m2424/2424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0106 - mae: 0.0712 - val_loss: 0.0633 - val_mae: 0.1871\n"
     ]
    }
   ],
   "source": [
    "neumf = NeuMF(data['NeuMF'], num_users, num_items)\n",
    "neumf_model = neumf.build_model()\n",
    "neumf_model = neumf.compile_model(neumf_model)\n",
    "\n",
    "mlp = MLP(data['NeuMF']['MLP'], num_users, num_items)\n",
    "mlp_model = mlp.build_model()\n",
    "\n",
    "gmf = GMF(data['NeuMF']['GMF'], num_users, num_items)\n",
    "gmf_model = gmf.build_model()\n",
    "\n",
    "# Verifying if we need to train MLP and GMF models\n",
    "mlp_weights_path = data['NeuMF']['MLP']['model_parameters_path']\n",
    "if os.path.exists(mlp_weights_path):\n",
    "    mlp_model.load_weights(data['NeuMF']['MLP']['model_parameters_path'])\n",
    "else:\n",
    "    mlp_model = mlp.compile_model(mlp_model)\n",
    "    neumf.train_MLP(mlp_model, user_train, item_train, rating_train, eval_data=(user_eval, item_eval, rating_eval))\n",
    "    mlp_model.load_weights(mlp_weights_path)\n",
    "\n",
    "gmf_weights_path = data['NeuMF']['GMF']['model_parameters_path']\n",
    "if os.path.exists(gmf_weights_path):\n",
    "    gmf_model.load_weights(data['NeuMF']['GMF']['model_parameters_path'])\n",
    "else:\n",
    "    gmf_model = gmf.compile_model(gmf_model)\n",
    "    neumf.train_GMF(gmf_model, user_train, item_train, rating_train, eval_data=(user_eval, item_eval, rating_eval))\n",
    "    gmf_model.load_weights(gmf_weights_path)\n",
    "\n",
    "neumf_model = neumf.load_pretrain_weights(neumf_model, mlp_model, gmf_model)\n",
    "history = neumf_model.fit([user_train, item_train], \n",
    "                          rating_train, \n",
    "                          validation_data=([user_eval, item_eval], rating_eval),\n",
    "                          epochs=data['NeuMF']['epochs'], \n",
    "                          batch_size=data['NeuMF']['batch_size'], \n",
    "                          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m808/808\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - loss: 0.0629 - mae: 0.1864\n"
     ]
    }
   ],
   "source": [
    "evaluation = neumf_model.evaluate([user_test, item_test], rating_test, batch_size=data['NeuMF']['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25853/25853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = neumf_model.predict([user_test, item_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_pred = pd.DataFrame({'True Values': rating_test, 'Predictions': predictions.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Values</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339578</th>\n",
       "      <td>0.7450</td>\n",
       "      <td>0.622734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341430</th>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.434920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389014</th>\n",
       "      <td>0.6260</td>\n",
       "      <td>0.649968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63147</th>\n",
       "      <td>0.6600</td>\n",
       "      <td>0.687414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631118</th>\n",
       "      <td>0.4685</td>\n",
       "      <td>0.625360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740944</th>\n",
       "      <td>0.6020</td>\n",
       "      <td>0.618596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767932</th>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.608797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192288</th>\n",
       "      <td>0.4685</td>\n",
       "      <td>0.656335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732701</th>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.306235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.681429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        True Values  Predictions\n",
       "339578       0.7450     0.622734\n",
       "341430       0.3105     0.434920\n",
       "389014       0.6260     0.649968\n",
       "63147        0.6600     0.687414\n",
       "631118       0.4685     0.625360\n",
       "740944       0.6020     0.618596\n",
       "767932       0.1480     0.608797\n",
       "192288       0.4685     0.656335\n",
       "732701       0.3860     0.306235\n",
       "27999        0.6725     0.681429"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_pred.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE):  0.06298968940973282\n",
      "Mean Absolute Error (MAE):  0.18659548461437225\n",
      "Root Mean Squared Error (RMSE):  0.2509774679323481\n"
     ]
    }
   ],
   "source": [
    "mse = evaluation[0]\n",
    "mae = evaluation[1]\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Squared Error (MSE): \", mse)\n",
    "print(\"Mean Absolute Error (MAE): \", mae)\n",
    "print(\"Root Mean Squared Error (RMSE): \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#neumf_model.save('./models/weights/neumf.h5')\n",
    "\n",
    "#20 epochs 808/808 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - loss: 0.0629 - mae: 0.1864"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(root) Python *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
