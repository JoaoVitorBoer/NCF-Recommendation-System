{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from models.MLP import MLP\n",
    "from models.GMF import GMF\n",
    "from models.NeuMF import NeuMF\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RATINGS_PATH = './data/preprocessed_data/ratings/ratings_preprocessed_ml.csv'\n",
    "JOKES_PATH = './data/preprocessed_data/jokes/jokes_preprocessed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"neumf-config.yaml\", \"r\") as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "ratings = pd.read_csv(RATINGS_PATH, sep=',', header=0)\n",
    "jokes = pd.read_csv(JOKES_PATH, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings['rating'] = (ratings['rating'] + 10) / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(ratings, shuffle=True, test_size=0.2, random_state=42)\n",
    "train_data, eval_data = train_test_split(train_data, shuffle=True, test_size=0.25, random_state=42)  \n",
    "\n",
    "user_train = train_data['user'].values\n",
    "item_train = train_data['joke_id'].values\n",
    "rating_train = train_data['rating'].values\n",
    "\n",
    "user_eval = eval_data['user'].values\n",
    "item_eval = eval_data['joke_id'].values\n",
    "rating_eval = eval_data['rating'].values\n",
    "\n",
    "user_test = test_data['user'].values\n",
    "item_test = test_data['joke_id'].values\n",
    "rating_test = test_data['rating'].values\n",
    "\n",
    "num_users = ratings['user'].nunique()\n",
    "num_items = ratings['joke_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neumf = NeuMF(data['NeuMF'], num_users, num_items)\n",
    "neumf_model = neumf.build_model()\n",
    "neumf_model = neumf.compile_model(neumf_model)\n",
    "\n",
    "mlp = MLP(data['NeuMF']['MLP'], num_users, num_items)\n",
    "mlp_model = mlp.build_model()\n",
    "\n",
    "gmf = GMF(data['NeuMF']['GMF'], num_users, num_items)\n",
    "gmf_model = gmf.build_model()\n",
    "\n",
    "# Verifying if we need to train MLP and GMF models\n",
    "mlp_weights_path = data['NeuMF']['MLP']['model_parameters_path']\n",
    "if os.path.exists(mlp_weights_path):\n",
    "    mlp_model.load_weights(data['NeuMF']['MLP']['model_parameters_path'])\n",
    "else:\n",
    "    mlp_model = mlp.compile_model(mlp_model)\n",
    "    neumf.train_MLP(mlp_model, user_train, item_train, rating_train, eval_data=(user_eval, item_eval, rating_eval))\n",
    "    mlp_model.load_weights(mlp_weights_path)\n",
    "\n",
    "gmf_weights_path = data['NeuMF']['GMF']['model_parameters_path']\n",
    "if os.path.exists(gmf_weights_path):\n",
    "    gmf_model.load_weights(data['NeuMF']['GMF']['model_parameters_path'])\n",
    "else:\n",
    "    gmf_model = gmf.compile_model(gmf_model)\n",
    "    neumf.train_GMF(gmf_model, user_train, item_train, rating_train, eval_data=(user_eval, item_eval, rating_eval))\n",
    "    gmf_model.load_weights(gmf_weights_path)\n",
    "\n",
    "neumf_model = neumf.load_pretrain_weights(neumf_model, mlp_model, gmf_model)\n",
    "history = neumf_model.fit([user_train, item_train], \n",
    "                          rating_train, \n",
    "                          validation_data=([user_eval, item_eval], rating_eval),\n",
    "                          epochs=data['NeuMF']['epochs'], \n",
    "                          batch_size=data['NeuMF']['batch_size'], \n",
    "                          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m808/808\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - loss: 0.0629 - mae: 0.1864\n"
     ]
    }
   ],
   "source": [
    "evaluation = neumf_model.evaluate([user_test, item_test], rating_test, batch_size=data['NeuMF']['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25853/25853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = neumf_model.predict([user_test, item_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_pred = pd.DataFrame({'True Values': rating_test, 'Predictions': predictions.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Values</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339578</th>\n",
       "      <td>0.7450</td>\n",
       "      <td>0.622734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341430</th>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.434920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389014</th>\n",
       "      <td>0.6260</td>\n",
       "      <td>0.649968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63147</th>\n",
       "      <td>0.6600</td>\n",
       "      <td>0.687414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631118</th>\n",
       "      <td>0.4685</td>\n",
       "      <td>0.625360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740944</th>\n",
       "      <td>0.6020</td>\n",
       "      <td>0.618596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767932</th>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.608797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192288</th>\n",
       "      <td>0.4685</td>\n",
       "      <td>0.656335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732701</th>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.306235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.681429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        True Values  Predictions\n",
       "339578       0.7450     0.622734\n",
       "341430       0.3105     0.434920\n",
       "389014       0.6260     0.649968\n",
       "63147        0.6600     0.687414\n",
       "631118       0.4685     0.625360\n",
       "740944       0.6020     0.618596\n",
       "767932       0.1480     0.608797\n",
       "192288       0.4685     0.656335\n",
       "732701       0.3860     0.306235\n",
       "27999        0.6725     0.681429"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_pred.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mse = evaluation[0]\n",
    "mae = evaluation[1]\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Squared Error (MSE): \", mse)\n",
    "print(\"Mean Absolute Error (MAE): \", mae)\n",
    "print(\"Root Mean Squared Error (RMSE): \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#neumf_model.save('./data/weights/neumf.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
